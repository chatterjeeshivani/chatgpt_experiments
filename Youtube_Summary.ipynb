{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYxQC3vYvDafSzVA0WFjA6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chatterjeeshivani/chatgpt_experiments/blob/main/Youtube_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "ooEIje9r1Knd",
        "outputId": "727273da-5c5a-42d3-c6ef-116db27e664c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "JK20WGTSp_gt",
        "outputId": "5c426ec0-7b91-4bff-e4e3-014c3e3bdfb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a18a8e9d-516b-4b11-bb5b-b08b71a0fea9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a18a8e9d-516b-4b11-bb5b-b08b71a0fea9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CHATGPT INTRO - Silicon Dojo Seminar.txt to CHATGPT INTRO - Silicon Dojo Seminar.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WLC3uiIVoT9O"
      },
      "outputs": [],
      "source": [
        "with open('open_api_key.txt', 'r') as f:\n",
        "    openai_key = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('CHATGPT INTRO - Silicon Dojo Seminar.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "woTszoEYp4bN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_id=\"585DQv6nmlo\""
      ],
      "metadata": {
        "id": "ufBQwecQgIxC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkY8q1gqKcy",
        "outputId": "c5ed4687-143d-435e-e24e-af54bc7cf757"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import re"
      ],
      "metadata": {
        "id": "zCjxiXiGqWDc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Divide the transcript into segments without cutting words\n",
        "def split_into_segments(text, max_segment_length=2048):\n",
        "    words = text.split()\n",
        "    segments = []\n",
        "    current_segment = []\n",
        "\n",
        "    for word in words:\n",
        "        if sum(len(w) for w in current_segment) + len(word) + len(current_segment) > max_segment_length:\n",
        "            segments.append(\" \".join(current_segment))\n",
        "            current_segment = []\n",
        "\n",
        "        current_segment.append(word)\n",
        "\n",
        "    if current_segment:\n",
        "        segments.append(\" \".join(current_segment))\n",
        "\n",
        "    return segments\n",
        "\n"
      ],
      "metadata": {
        "id": "eXgt9ZIp1Abu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments = split_into_segments(text)\n"
      ],
      "metadata": {
        "id": "GFjW_MUB1W_q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(segments))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwlHs4Dw1ZCz",
        "outputId": "129b5823-9322-4db3-eca9-b4a27efe2b75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(segments)"
      ],
      "metadata": {
        "id": "TMlUM1Bb1epk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key=openai_key"
      ],
      "metadata": {
        "id": "YQSdCNSHAT0f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(segment):\n",
        "    prompt=f\"Imagine you're presenting the key points from the transcription to a group of colleagues. Write a concise summary of what was discussed and any relevant details that may be important to your audience:\\n\\n{segment}\\n\\nSummary:\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "    )\n",
        "    summary = response.choices[0].message.content.strip()\n",
        "    #print(summary)\n",
        "    return summary\n",
        "    #print(response)\n",
        "\n"
      ],
      "metadata": {
        "id": "YsiwJ-mR1m12"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_summary(segments[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "nvfI0INLAKed",
        "outputId": "c060306b-4a5a-4d6b-a3d1-a76a23b1c122"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The speaker introduces Silicon Dojo, a technology education program in Asheville, North Carolina, that is free to end-users but relies on donations to cover costs. The seminar topic is the Chat GPT API, specifically the DaVinci model, as the newest version, Chat GPT4 API, is not widely available to most people. The speaker will also demonstrate the 3.5 model, Dolly for image creation, and Whisper for audio transcription. The audience is encouraged to support the program through donations.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The speaker introduces Silicon Dojo, a technology education program in Asheville, North Carolina, that is free to end-users but relies on donations to cover costs. The seminar topic is the Chat GPT API, specifically the DaVinci model, as the newest version, Chat GPT4 API, is not widely available to most people. The speaker will also demonstrate the 3.5 model, Dolly for image creation, and Whisper for audio transcription. The audience is encouraged to support the program through donations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#segments[0]"
      ],
      "metadata": {
        "id": "plgcbrs7aaxe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = [generate_summary(segment) for segment in segments]"
      ],
      "metadata": {
        "id": "pI9RehuZAPTz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summaries"
      ],
      "metadata": {
        "id": "GayYP6coDEuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Combine the summaries to create a step-by-step summary of the podcast\n",
        "\n",
        "final_summary = \"\\n\".join(summary for summary in summaries if summary is not None)\n",
        "print(\"Step-by-step summary of the podcast:\")\n",
        "print(final_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2F56lnfA1Qx",
        "outputId": "8d836776-a0d3-48fe-caaf-860fa25251d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step-by-step summary of the podcast:\n",
            "Eli the computer guy is presenting a seminar on the chat GPT API at Silicon Dojo, a free technology education platform in Asheville, North Carolina. Although the seminar was initially on the chat GPT 3.5 model, Eli also demonstrates how to use the DaVinci model, Dolly (an image creation model), and Whisper (an audio tool for text transcription). Eli mentions that the new chat GPT 4 API has been recently released but is not available to most people as they are on a waitlist. Silicon Dojo is run on donations and links to their donor box are available for support.\n",
            "In the seminar, the speaker explains why it is important to watch even if a particular chatpt model may be obsolete, as older models may have unique functions and ways of speaking which could still be relevant. Participants will learn how to parse the text response from the AI and format it into something that the end user will find valuable. The 3.5 turbo model has a politically correct tone which can result in verbose and sometimes worthless sentences. The 3.0 model, on the other hand, does not have this issue and can give a cleaner response to end users. As a coder, it is essential to understand the unique features of each model to choose which one to use for different projects.\n",
            "The speaker advises using an older model for chat kpt 4.0 as it will be cheaper and easier to parse responses. They also reveal a secret that technology professionals get paid a lot of money for doing tasks that are not actually complicated, and users shouldn't be afraid of artificial intelligence as APIs can give access to AI with minimal coding knowledge. Serverless architecture is highlighted as a modern approach.\n",
            "The speaker discusses the ease of using Open AI's infrastructure through APIs to get responses to queries, emphasizing that it only takes a few lines of Python code. They caution that technology professionals should also focus on legal and regulatory aspects and maintenance contracts, as a significant portion of their day may be spent on these tasks rather than coding.\n",
            "The discussion highlights the issue of copyright protection in relation to artificial intelligence (AI). Due to the legal system in the United States, copyright protection is granted to humans for their creations, such as pictures, scripts or books. However, if AI creates something, there is no copyright protection. The lack of copyright protection creates confusion, as in the case of the monkey selfie picture where a photographer got sued for not having the copyright, as the monkey had taken the picture. The discussion emphasizes the importance of addressing this issue as AI becomes more prevalent in creative industries.\n",
            "A court case has determined that using an AI graphics generator in creating pictures for a copyrighted comic book means the pictures are not copyrightable. This has important implications for creators who use AI in their work as they may not own the copyright to those works. This could lead to legal consequences and issues with piracy, especially for startups who may not want to pay for graphic design work. It is important to understand the limitations of AI in terms of copyright ownership.\n",
            "The discussion centered around the importance of protecting copyright and the potential pitfalls of using copycat graphic design services like Dolly. It was suggested that it may be more beneficial to hire a graphic designer to own the copyright of the material created. The discussion also touched upon the use of tokens as the currency of the chat GPT world, which can be confusing due to the varying length and structure of the tokens. However, tokens are relatively inexpensive and have value within the chat GPT system. It was advised to keep these factors in mind for anyone involved in designing or using AI-generated content.\n",
            "The speaker discusses the pricing model of the ChatGPT API and explains that tokens are used for both the query and response. The pricing model may seem wonky and may require consideration, particularly in the Enterprise world wherein there is heavy usage of the API. The cost of the query may exceed the response cost, particularly with ChatGPT4's ability to take in 16 pages of information in a query. In general, the cost of queries is inexpensive and may not be a concern for onesies-twosies. When you first use the API, 18 free credits are given.\n",
            "The discussion covered the pricing models for OpenAI's GPT-3 platform, which uses tokens to measure the cost of each query or response on the system. The tokens are inexpensive, but costs can add up quickly when dealing with large volumes of users. The chat GPT 3.5 turbo model costs one-fifth of a penny for 1,000 tokens, making it an affordable option for most users. However, the dolly model, which generates images based on queries, can be costly and should be approached with caution.\n",
            "The transcription discusses the different image sizes and resolutions available on Dolly, with the cost per image increasing as the resolution increases. While Dolly is an inexpensive tool, using it to generate images can become expensive due to the need to generate multiple images to find one usable one. Additionally, the text generation service is inexpensive but the image generation can quickly eat through a budget. To use Dolly, users have to set up an account and can set monthly limits to control costs.\n",
            "In the transcription, it is recommended to set a monthly cap on chat QPT spending to prevent accidentally hammering the API and spending a large amount of money. Different models for chat QPT are discussed, including GPT 3.5 turbo and DaVinci zero zero three, with different capabilities and costs. The importance of considering when the training data has been updated is also emphasized.\n",
            "The discussion highlighted two language models, DaVinci and Turbo, with DaVinci having better quality, longer output, and consistency in following instructions. It was emphasized that switching models would affect the query input and response parsing. The importance of understanding the practical differences between the models was also highlighted, with a practical example provided through code to show the difference in verbosity.\n",
            "The presentation discussed using an API key in Python to utilize the open AI module. The API key should be stored in an environment variable to prevent access to it. The open AI module must be imported and installed using pip. To create a query, the chat EPT function is used with the model to send the question and receive a response. These steps were demonstrated with an example question, \"Does God exist?\"\n",
            "The discussion revolves around the use of the OpenAI completion tool, specifically the DaVinci model. The key points discussed include the importance of setting the temperature and max token parameters to fine-tune the quality of the answer generated. The speaker also emphasizes the need to ensure that enough tokens are given, as failing to do so may result in a response that cuts off abruptly. Finally, the group is shown how to print out the response using the DaVinci format, which involves indexing the response and printing it out as a text.\n",
            "The discussion revolves around the concept of God and how different AI language models provide different answers to the question of God's existence. It is important to consider the speed and relevance of the responses before using a particular model. The answer to the question of God's existence is a matter of personal beliefs and opinions, which vary with individual perspectives. As a technology professional or coder, it is crucial to parse the relevant response and remove any irrelevant information to provide a concise and clear answer to the users. Choosing the latest model may not necessarily be the best option, and one should consider which model provides the most useful response.\n",
            "The speaker discusses how to parse the response when using chat TPT 3.5 versus chat GPT 3.0. The end points are how the response is sent back to you, and in the Python world, named key arrays are called dictionaries and standard arrays are called lists. To print out the text, you need to understand how to get to that level, and for chat GPT 3.5, the response is opened up as a dictionary with a list, with the text located under message content. Overall, this information will be helpful for coders trying to work with version 4.0.\n",
            "This discussion focuses on the use of GPT 3.0 and Text Defensory DaVinci 03 in chat responses. The speaker explains the need to understand how lists and dictionaries work when trying to retrieve specific values from the response. They also mention the importance of formatting responses in order to print out the text successfully. The presentation will include demonstrations of the DaVinci model to showcase the chat response capabilities.\n",
            "The discussion focuses on using DaVinci, an artificial intelligence tool, to complete tasks such as writing codes, blog posts, and communicating with an employee. The code for DaVinci is shown, and the steps are explained in detail, including importing the open AI module, adding API key, sending a prompt to chat GPT, and getting back the text from the response. The speaker demonstrates this by asking DaVinci to tell a story about a frog and a unicycle. The use of temperature, top P frequency, and presence are discussed briefly, and the need for playing with those parameters depends on the task at hand.\n",
            "The discussion centered around the DaVinci test by OpenAI, which uses Python 3 to generate stories based on a given prompt. The speaker demonstrated how the test worked by inputting a prompt about a frog and a unicycle, and the test generated a full story about Fred the Frog riding the unicycle. The speaker praised the quality of the writing and suggested that the DaVinci test could be used for storytelling purposes.\n",
            "The speaker discusses how they deal with various coding languages and technologies to solve problems in their work. They talk about their use of Django, a python web app framework, and how to turn a query set into a dictionary using the dot values method. They also discuss the value of using open AI DaVinci to quickly find solutions to coding problems and how it benefits their work with both Python and JavaScript.\n",
            "The transcription discusses a tool that spits out an answer to a question and allows the user to try again or ask the question differently. The tool can also format text in HTML, which is useful for blog posts and articles. An example is given of asking how to pour a cup of milk and receiving a response with instructions formatted in HTML. The tool can be used for creating blog posts or articles and the formatted response can be directly inserted into a database.\n",
            "The discussion revolves around the use of AI in creating automatic web pages, chatbots for sales communication, and the potential drawbacks of increased AI-generated spam. Salesforce plans to replace cold calling tasks for salespeople with AI-generated cold emails. The speaker demonstrates how OpenAI DaVinci can be used to create a personalized email to a potential client. The speaker expresses concern about the inevitable increase in AI-driven spam.\n",
            "The speaker discusses the 3.5 turbo model and its differences from the previous DaVinci model. The coating is different, but it is not too complicated. The model allows for assigning roles to nudge it in a specific direction, which is useful for reusability. They provide an example where the answer depends on the user's location, and roles can be used to provide the correct answer. Finally, they show an example of the code for the 3.5 turbo model, including importing the open AI module, using the API key, and creating a variable value to tweak the response.\n",
            "The discussion revolves around using chat GPT 3.5 to refine answers to questions. To do so, the system has three roles - system, assistant, and user. The system role defines the character profile of the chatbot, which affects the grammar and tone of the response. The assistant role nudges the question in a particular direction by specifying the answer as per a variable value, such as a citizen of a particular country. The user is the question being asked. Multiple assistant roles can be used to bias the response towards a particular demographic. The aim is to get the most appropriate answer for a specific demographic, such as a woman living in California.\n",
            "The speaker discusses using open AI Turbo to create a web application that can give responses to questions based on given information. The application can be biased depending on the user's assistant information. The response is printed out along with the user's text. The speaker gives an example of asking about the leader of the United States and Brazil in the year 2000, and the web application provides a response and additional information. There is some discussion about the speed and verbosity of the response.\n",
            "The transcript covers various topics including the presidency of Brazil, AI technology, and how to customize answers for users. The focus is on the power of AI to personalize responses based on user demographics and information, and how concatenating additional information can skew the answers in a preferred direction. The importance of providing accurate responses to users is also discussed, as people tend to trust computers as being right. Overall, the discussion highlights the potential of AI technology in delivering tailored responses to users.\n",
            "The discussion covered the idea of using AI as a way to validate personal viewpoints, the importance of considering the human condition when developing technology, and the use of loops and variable values in creating an app. The speaker emphasized the need to add a human touch to apps and to remember that technology is used to solve human problems. The session also included an example of how to concatenate additional information into a script and loop through it to give different responses based on the person asking the question. The app in question was based on the 3.0 da Vinci model and used the Open AI module with an API key.\n",
            "The discussion revolves around a list called Slant which includes different groups such as Christians, scientists, pastafarians, Republicans and Democrats. The main focus is to determine the bias of the chatbot towards these groups and how it answers a particular question regarding the beginning of the world. The process involves a for-each loop for each value in the slant list, submitting the question and concatenating it with a prompt. The temperature is fixed at 60 while max tokens don't matter. The output is the answer of the chatbot and this exercise is to see how the bias of chatbots can skew the answers to a particular question.\n",
            "The transcript discusses different beliefs about how the world began from a Christian, scientific, and Pastafarian perspective. It also highlights biases that can be introduced based on political affiliations, with Republicans believing in God's creation and Democrats subscribing to the Big Bang Theory. The speaker emphasizes the importance of concatenation to ensure proper answers from an AI model.\n",
            "The discussion is about a tool that can automate the formatting of blog posts by prompting the user with questions and concatenating them into HTML code. This can also be used to adapt language and syntax to cater to a target market. The conversation then moves onto using Dolly, which is a tool that generates images based on prompts, but can also be quite creepy.\n",
            "The speaker discusses the use of Dolly, a language model developed by OpenAI, and how to ensure that embedded images in websites using Dolly's generated URLs do not disappear after an hour. The speaker also shares examples of some of the odd and sometimes creepy responses generated by Dolly when given various prompts, both normal and nonsensical.\n",
            "The speaker discussed using OpenAI to generate images based on prompts, such as a kid using a computer or a goat in World War II. They emphasized the cost, which is 10 cents per five images at 256 size. The speaker also explained the process of embedding the generated images into a document. They also mentioned a joke about a Republican in love with a sheep, which led to amusing responses.\n",
            "The speaker demonstrates how to use Python to embed images from a website onto a single page with IMG SRC. They use odd examples such as a goat riding a cow and a kid riding a llama to show how to process the URLs and print out the response. They showcase how the webpage is automatically recreated each time it is refreshed, with multiple images to choose from. Additionally, they briefly mention that Dolly and human faces are weird.\n",
            "The transcription discusses using APIs to transcribe image and audio files. The speaker mentions the ease of use and simplicity of the Whisper API for transcribing audio files, and notes that it currently does not require tokens, but may in the future. The speaker also mentions the ability to translate languages into English but not from English, and demonstrates a simple code for using the Whisper API.\n",
            "The transcription discusses how to use AI technology to transcribe audio files into text files. This involves using a Python script and a specific API, such as Whisper, to transcribe the audio file. The speaker also provides tips for recording audio, exporting MP3 files, and working with ASCII text. The key takeaway is that dealing with audio files is difficult, but turning them into text files is much easier with the right tools.\n",
            "The discussion was focused on the capabilities of a new web app called Whisper which can convert audio files into MP3s and then text which can be used to parse for commands such as asking for the weather. The talk also touched on the China GPT API's moderation service which can scan communications for hatefulness or red flags, making it useful for internal communication management. The speaker also commented on the overblown perception of leaders and managers on platforms like LinkedIn.\n",
            "The discussion focuses on the importance of managers to identify and support struggling employees. Managers often get tunnel vision and only focus on the best or worst performers, but middle employees are also important and need attention. AI systems can be helpful in monitoring and identifying potential problems before they escalate. It is suggested to have a single pane of glass to look at the analytics of what's going on with overall your institution.\n",
            "The discussion focused on using computer algorithms to monitor the tone and language used in internal employee communication. The aim would be to identify spikes in negative emotions such as frustration and hate speech before they escalate into larger problems like harassment or discrimination lawsuits. This method is seen as useful for companies to address bullying and communication issues between employees as they may not be aware of the tone or language being used in private employee communication. The process involves importing the necessary modules and feeding the database input to get the output.\n",
            "The speaker discussed the importance of using the moderation API to monitor and prevent inappropriate content in a business environment. They explained the different categories within the API, including hate, self-harm, sexual content, and violence. They emphasized the need to address any concerning behavior from employees, such as expressing a desire to harm others or themselves. The speaker demonstrated how the API generates true/false responses and number scores to identify problematic content. The presentation urged the use of moderation tools to maintain a safe and appropriate workplace.\n",
            "The discussion was about using an API to analyze text data from various communication platforms, such as messaging systems, email, and social media, to identify patterns and deviations in language usage by employees. By doing so, managers can obtain a baseline understanding of how their employees communicate, detect deviations from the norm, and take necessary actions to reduce the risk of potential problems, such as harassment, self-harm, or legal issues. The API was also useful in identifying user abuse and end-users.\n",
            "The discussion touched on the importance of avoiding API violations, especially when it comes to sensitive topics such as child pornography or discussing ways to harm someone. The speaker suggested adding a user variable to identify who is responsible for API violations, as this can help prevent the account from being flagged or suspended. Additionally, when using chat GPT or any AI solution, caching results is recommended to avoid constantly paying for the same images repeatedly.\n",
            "The discussion focused on efficient ways to handle chat responses without repeatedly requesting the same types of images. The suggestion was to automatically download them into a data store for future use, which could also benefit others in the organization. The importance of caching GPT results was emphasized, as well as the value of editing responses to be more appropriate for the environment. The goal is to avoid API fees and create a better user experience for the company's web app.\n",
            "The discussion focused on the potential drawbacks of excessive API usage, with a suggestion to reduce usage fees. There was also a recommendation to prioritize operational security, particularly through local infrastructure and caching. The use of chat GPT and other AI solutions has the potential for self-learning, but caution should be exercised in copying proprietary code to prevent potential vulnerabilities and leakage of trade secrets.\n",
            "The speaker advises caution when using APIs, as you may not know what the vendor is doing with the queries or how they are logging information. It is important to only send necessary information and sanitize it beforehand. There is also a risk of leaked API keys in AI solutions, so sanitization within apps should be considered. It's important to build for a zero trust environment and be aware of competitors. GPT4 is an upcoming API that you can join a waitlist for, but the seminar did not cover it.\n",
            "The discussion was about the importance of remaining relevant in the face of new technology and how DaVinci may still be better at solving problems than the newest model. Learning Python is recommended for those interested in playing with the GPT API, as open AI seems to be very friendly with Python. There are ways to work around the system if one knows a different coding language, but Python is the way to go. It was also mentioned that signing up for the chat GPT API initially gives 18 in credit.\n",
            "The speaker discusses the GPT API and how it provides a certain amount of credit when signing up. It becomes more costly when dealing with images, but users can continuously play with AI by entering their credit card information. The speaker also talks about the concept of scaling Silicon Dojo and how it relates to martial arts, encouraging listeners to take what they learn and teach it to others. The speaker shares examples of how their YouTube videos have helped people in various parts of the world.\n",
            "The speaker discussed their experience running Silicon Dojo, an educational program teaching coding and technology skills. They emphasized the potential for others in different locations to use their model and create their own version of the program, with minimal resources needed. The speaker provided code for others to download and modify as needed. They encouraged attendees to use education to empower those around them, adapting the program to fit their specific needs and aspirations.\n",
            "The speaker plans to focus more on hands-on classes in addition to seminars. There will be exercises to do during the classes, rather than just listening to the speaker talk for long periods of time. The goal is to prevent students from falling asleep during sessions. The speaker mentioned doing one to three-hour introduction classes for Python, followed by more advanced classes on specific projects, where students can be hands-on and build something. The speaker believes this approach will keep students awake and help them feel more comfortable with the material.\n",
            "The speaker suggests creating blocks of classes on Python for education, covering various topics like databases, chat EPT, machine vision, etc. These blocks can be combined to create full-day classes and boot camps. The goal is to offer hands-on classes that can be replicated and chosen as per the student's interest. The success of this approach is yet to be seen, and the speaker invites interested individuals to attend in-person or watch on YouTube.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "83zR_WFIBa-f",
        "outputId": "1b8073d0-7f70-4edc-ab14-9001105484a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/summaries/youtube/'+video_id+'.txt'\n"
      ],
      "metadata": {
        "id": "R7ZnzfXIf7kx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, 'w') as f:\n",
        "    f.write(final_summary)"
      ],
      "metadata": {
        "id": "SUJHN1MqgR0V"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WG7CYP4RgVhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}